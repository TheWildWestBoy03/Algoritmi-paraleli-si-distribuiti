### Nume: Pogan Alexandru-Mihail
### Grupa: 335CA

# Algoritmi paraleli si distribuiti: Tema 1a - Calculul paralel al unui index inversat folosind paradigma Map-Reduce

<p style="font-size:17px; text-indent:40px">In cadrul acestei teme a fost realizat un algoritm paralel pentru determinarea indexului inversat folosind paradigme Mapper-Reduce, o tehnica des folosita in cadrul sistemelor paralele si distribuite in vederea obtinerii rapide si eficiente a informatiilor. </p>
<p style="font-size:17px; text-indent:40px">In acest scop, am implementat doua tipuri de threaduri, si anume Mappers si Reducers, fiecare cu rolul sau bine definit. Mapperii se ocupa cu citirea fisierelor din fisierul de test obtinut din linia de comanda, precum si salvarea cuvintelor intr-o structura de tip {cheie: valoare}, in acest caz o structura de map, cu cheia fiind id-ul fisierului, iar valoare fiind un set de cuvinte, in timp ce Reducerii se ocupa de agregarea listelor partiale rezultate in urma threadurilor Mapper, de clasificarea in functie de litera din alfabet cu care fiecare cuvant incepe, precum si cu sortarea intrarilor destinate, in functie de numarul de fisiere in care cuvantul respectiv apare, dar si cu scrierea intrarilor sortate in fisierele output destinate thread-ului.</p>
<p style="font-size:17px; text-indent:40px">Astfel, pentru inceput, threadul Main imparte sarcina aka fisierele de input Mapperilor, static, impartind cat de echitabil se poate in functie de dimensiunile fisierelor. La fiecare pas, verific daca size-ul cumulat al fisierelor anterior gestionate depaseste pragul definit de media dimensiunilor fisierelor de input. In acest caz, definesc o structura de argument pentru mapper, resetand suma dimensiunilor fisierelor de dinainte. Aceasta procedura este realizata ulterior citirii din fisierul de test, pentru a obtine numele fisierelor de input. Tot threadul principal initializeaza parametrii si structurile partajate intre thread-uri, iar la final elibereaza memoria. </p>
<p style="font-size:17px; text-indent:40px"> In Mapper, pentru fisierul i din iteratia principala, initializez fisierul si citesc continutul acestuia cuvant cu cuvant. Apoi, cu un mutex iau cuvintele si le introduc rand pe rand in dreptul id-ului corect. Aici se foloseste set, intrucat acesta nu contine elemente duplicate, insa sunt sortate mereu. </p>
<p style="font-size:17px; text-indent:40px"> La final, in reducer iau structura rezultata in urma actiunii Mapperelor, imi iau o structura de tip map, cu cheia fiind cuvantul, iar valoarea fiind vectorul de id-uri de fisiere in care cuvantul se afla. Ulterior, pentru agregare convertesc structura data de la Mappere in structura noua. Acest proces este realizat in paralel, tinandu-se cont de o serie de bound-uri care reprezinta id-urile fisierelor de input, distribuite egal reducerilor. De asemenea, imi mai calculez niste bounduri, ce vor fi folosite pana la terminarea executiei reducerelor. Acestea se calculeaza folosind un vector de frecvente, convertit in vector de sume partiale. Ulterior, intrarile din map-ul rezultat se salveaza intr-un vector partajat, care se sorteaza dupa numarul de elemente din valoarea vector, precum si lexicografic, sortare realizata in paralel pe bucati. La final, bucatile din vector se salveaza in fisierele de output asignate fiecarui reducer, cu ajutorul unor bound-uri calculate de catre fiecare reducer.
